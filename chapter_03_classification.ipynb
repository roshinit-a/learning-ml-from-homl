{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0ab494",
   "metadata": {},
   "source": [
    "Alright, great job finishing Chapter 2! We've built a solid foundation in regression, where you predicted a *value* (like a house price).\n",
    "\n",
    "Now, let's move on to **Chapter 3: Classification**. This is a different beast. Instead of predicting a number on a continuous scale, we're going to predict a **class** or a **category**. Think of it like sorting mail into different bins (bin '0', bin '1', bin '2', etc.) rather than estimating the postage cost.\n",
    "\n",
    "---\n",
    "\n",
    "# **Our New \"Hello, World!\" - The MNIST Dataset**\n",
    "In programming, the first thing we always do is print \"Hello, World!\". In machine learning, the \"Hello, World!\" for classification is the **MNIST dataset**.\n",
    "\n",
    "- **What it is:** A big collection (70,000) of small, 28x28 pixel images.\n",
    "\n",
    "- **What's in the images:** Handwritten digits (0 through 9) written by high school students and US Census Bureau employees.\n",
    "\n",
    "- **Why it's famous:** It's a standard benchmark. When someone invents a new classification algorithm, they test it on MNIST to see how it performs against other algorithms. It's the perfect dataset for us to start with.\n",
    "\n",
    "---\n",
    "\n",
    "## **Getting the Data with Scikit-Learn**\n",
    "\n",
    "First, we need to load this dataset. Scikit-Learn has a whole module, `sklearn.datasets`, to help with this. It has three main types of functions:\n",
    "\n",
    "1. `fetch_*`: Used to download **real-world datasets** from the internet (like `fetch_openml()`). This is what we're using.\n",
    "\n",
    "2. `load_*`: Used to load **small, toy datasets** that come bundled *with* Scikit-Learn. These are good for quick tests.\n",
    "\n",
    "3. `make_*`: Used to **generate fake datasets** for testing specific algorithm behaviors.\n",
    "\n",
    "The code in the book uses `fetch_openml()` to get MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f298ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b2a37",
   "metadata": {},
   "source": [
    "The important part here is `as_frame=False`. By default, this function might give you the data as a Pandas DataFrame. But for images, it's *much* easier to work with NumPy arrays. Setting `as_frame=False` tells Scikit-Learn, \"Just give me the raw NumPy data.\"\n",
    "\n",
    "---\n",
    "\n",
    "## **Looking at Our Data (X and y)**\n",
    "The `mnist` object that's returned is a `Bunch` object, which is like a dictionary. We can grab the two most important pieces:\n",
    "\n",
    "`mnist.data`: The features (the images themselves). We'll call this `X`.\n",
    "\n",
    "`mnist.target`: The labels (what digit each image represents). We'll call this `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f900715",
   "metadata": {},
   "source": [
    "Let's look at their shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7e2879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6496d6a",
   "metadata": {},
   "source": [
    "`X.shape` **is** `(70000, 784)`\n",
    "\n",
    "This is the most important concept to understand.\n",
    "- **70,000:** This is easy. It's the number of images in our dataset.\n",
    "- **784:** Where does this number come from?\n",
    "  - Each image is $28 \\times 28$ pixels.\n",
    "  - To make it \"machine learning friendly,\" the 2D image has been **\"flattened\"** into a single 1D row.\n",
    "  - $28 \\times 28 = 784$.\n",
    "  - So, each row is one image, and each of the 784 columns is the **intensity of a single pixel** (from 0 for white to 255 for black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3e4a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c33426d",
   "metadata": {},
   "source": [
    "`y.shape` **is** `(70000,)`\n",
    "\n",
    "This is a 1D array with 70,000 entries. It's our list of labels. The first entry in `y` ( `y[0]` ) is the correct digit for the first image in `X` ( `X[0]` ).\n",
    "\n",
    "When you check `y[0]`, the book says it's `'5'`. This tells us the first image in our dataset is supposed to be the digit 5.\n",
    "\n",
    "---\n",
    "\n",
    "## **How to \"See\" a Flattened Image**\n",
    "\n",
    "We can't make sense of a row of 784 numbers. To prove to ourselves that `X[0]` is really a '5', we have to reverse the flattening. We need to take that 1D array of 784 features and **reshape** it back into its original 2D $28 \\times 28$ grid.\n",
    "\n",
    "That's exactly what the `plot_digit` function does:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9304b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def  plot_digit(image_data):\n",
    "    # Reshape the 1D array (784, ) into a 2D array (28, 28)\n",
    "    image = image_data.reshape(28, 28)\n",
    "\n",
    "    # Use matplotlib's imshow() to display the 2D array as an image\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "for i in range (0, 1): # Grab the first image's data\n",
    "    some_digit = X[i]\n",
    "    plot_digit(some_digit)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819ae3e",
   "metadata": {},
   "source": [
    "When you run this, you'll see the image of the handwritten \"5\".\n",
    "\n",
    "---\n",
    "\n",
    "## **The Golden Rule: Create a Test Set First**\n",
    "\n",
    "This is **critical**. Before you do *any* data exploration or model training, you **must** set aside your test data.\n",
    "\n",
    "Think of it like an exam. If you study using the *actual* exam questions (the test set), you'll get a perfect score, but you won't have *learned* anything. You'll fail when you see a new, *different* exam.\n",
    "\n",
    "Your model is the same. It can \"cheat\" by memorizing the test set's answers (this is called **overfitting**). We must hide the test set and *only* use it for the final evaluation, just once.\n",
    "\n",
    "Fortunately, the MNIST dataset from `fetch_openml()` is already organized for us:\n",
    "\n",
    "- **Training set:** The first 60,000 images.\n",
    "\n",
    "- **Test set:** The last 10,000 images.\n",
    "\n",
    "So, we can easily split it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c955335",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abef452",
   "metadata": {},
   "source": [
    "### **A Note on Shuffling**\n",
    "The book mentions the training set is already shuffled. This is a good thing!\n",
    "\n",
    "1. It ensures **cross-validation** (which we'll learn about soon) works well. We don't want one \"fold\" of our data to *only* have 0s and 1s, and another to *only* have 8s and 9s. Shuffling mixes them up.\n",
    "\n",
    "2. Some algorithms (like Stochastic Gradient Descent) are sensitive to order. They learn poorly if you show them 1,000 pictures of a \"5\" in a row. Shuffling solves this.\n",
    "\n",
    "## **Our Mission**\n",
    "That's the setup! We've moved from regression to classification, we've loaded the famous MNIST dataset, we've understood its 784 features, and we've correctly (and *very* importantly) split it into a training and a test set.\n",
    "\n",
    "Now we're ready to start building our first classifier. Let's get to it!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739402e4",
   "metadata": {},
   "source": [
    "## **Training a Binary Classifier**\n",
    "\n",
    "Alright, let's break this down. This is a very important step in our machine learning journey.\n",
    "\n",
    "We have a big, complicated problem: we want to identify *all* *10* *digits* (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). This is called **multiclass classification**.\n",
    "\n",
    "But as a smart learning strategy, we're going to start simpler. Instead of building a complex model to sort images into 10 different bins, let's just build a model that sorts them into *two* bins. This is a **binary classifier** (\"bi\" meaning two).\n",
    "\n",
    "Our simple question will be:\" **\"Is this a 5?** (Yes/No).\n",
    "\n",
    "The two classes (bins) are:\n",
    "\n",
    "1. **\"5\"**: This is our *positive* class.\n",
    "\n",
    "2. **\"non-5\"**: This is our *negative* class (it includes 0s, 1s, 2s, 3s, 4s, 6s, 7s, 8s, and 9s).\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Creating the New \"Answer Key\"**\n",
    "Our original \"answer key,\" `y_train`, looks like this: `['5', '0', '4', '1', '9', ...]`. Our new, simple classifier doesn't understand all those digits. It only understands \"Yes\" or \"No\" (which we represent with `True` or `False`).\n",
    "\n",
    "We need to create a new answer key. The code does this very cleverly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a925bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500f8aa",
   "metadata": {},
   "source": [
    "Let's look at that first line. It goes through every single label in `y_train` and performs a check: \"Is this label equal to `'5'`?\"\n",
    "\n",
    "- If `y_train[0]` is `'5'`, then `y_train_5[0]` becomes `True`.\n",
    "\n",
    "- If `y_train[1]` is `'0'`, then `y_train_5[1]` becomes `False`.\n",
    "\n",
    "- If `y_train[2]` is `'4'`, then `y_train_5[2]` becomes `False`.\n",
    "\n",
    "- ...and so on.\n",
    "\n",
    "So now, `y_train_5` is our *new* target vector (our new answer key) that looks like: `[True, False, False, ...]`. This is *exactly* what our \"5-detector\" needs to learn from. We do the same for our test set.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Choosing the Algorithm:** `SGDClassifier`\n",
    "Now we need to pick a learning algorithm (a \"classifier\"). The book suggests a great starting point: **Stochastic Gradient Descent (SGD) Classifier.**\n",
    "\n",
    "Let's break down that name:\n",
    "\n",
    "- **Classifier:** It classifies things. Easy.\n",
    "\n",
    "- **Gradient Descent:** This is the \"learning\" technique. Imagine you're on a foggy mountain and want to find the lowest valley. You check the slope (the \"gradient\") around you and take a step downhill (\"descent\"). You repeat this until you're at the bottom. In ML, the \"valley\" is the point with the *lowest* *error*.\n",
    "\n",
    "- **Stochastic:** This is the *most* important part. \"Stochastic\" just means \"random.\" Instead of checking the *entire* mountain's slope (which would mean looking at all 60,000 training images at once!), you just pick **one random training instance* at a time. You look at that single image, calculate the error for *it*, and take a small step downhill. Then you pick another random instance, and so on.\n",
    "\n",
    "#### **Why is SGD so good?** \n",
    "It's incredibly **fast and memory-efficient**. Because it only looks at one instance at a time, you can train it on *massive* datasets (billions of instances!) that would never fit in your computer's RAM. It also makes it possible to do \"online learning,\" where we can keep feeding the model new data as it arrives.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Training the Model (The** `fit` **command)**\n",
    "This is where the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4eb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 1. We create an instance of the classifier\n",
    "#    random_state=42 just make sure we get the same \"random\"\n",
    "#    start each time, so our result are reproducible\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "# 2. We train the model\n",
    "sgd_clf.fit(X_train, y_train_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905f261",
   "metadata": {},
   "source": [
    "The `.fit()` method is the \"study\" command. We're telling our `sgd_clf`:\n",
    "\n",
    "- \"Here are all the images (`X_train`).\"\n",
    "\n",
    "- \"And here is the '5' or 'not-5' answer key for them (`y_train_5`).\"\n",
    "\n",
    "Now, the `SGDClassifier` goes to work. It will loop through the training data (one instance at a time, because it's *stochastic*), making a guess, checking its guess against the `y_train_5` answer, and slightly adjusting its internal parameters to get better. It does this over and over until it has a good model of what separates a \"5\" from a \"non-5\".\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Making a Prediction (The \"Pop Quiz\")\n",
    "The training is done. Our classifier has \"studied.\" Now let's give it a pop quiz. We'll use that `some_digit` variable from before (which was `X[0]`, the image of the '5')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a3bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit = X[0]\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37b278",
   "metadata": {},
   "source": [
    "- `sgd_clf.predict(...)`: We're asking our trained classifier to make a prediction.\n",
    "\n",
    "- `[some_digit]`: We wrap `some_digit` in square brackets `[]` because the `predict` method expects a *list* of images, even if we're only sending one.\n",
    "\n",
    "- `array([ True])`: This is the classifier's answer! It says, \"I predict that this image is in the `True` class.\" And since `True` means \"it's a 5,\" our classifier got this one right! ðŸ¥³\n",
    "\n",
    "**But hold on!** Just because it got *one* right doesn't mean it's a good model. What if it gets all the *other* ones wrong?\n",
    "\n",
    "That's why the very next step, as the book says, is to **evaluate its performance** properly. We can't just trust one example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739df9c",
   "metadata": {},
   "source": [
    "---\n",
    "# **Peformance Measure**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdaa3c",
   "metadata": {},
   "source": [
    "## **Measuring Accuracy Using Cross-Validation**\n",
    "\n",
    "Ah, this is one of the most important lessons in all of machine learning! Let's get a coffee and dive in.\n",
    "\n",
    "So, we've trained our \"5-detector\" model. Our gut feeling is to ask, \"What *percentage* did it get right?\" That's what we call **accuracy**.\n",
    "\n",
    "### **Part 1: The \"Amazing\" (but Misleading) Score**\n",
    "The easiest way to check this is to use **cross-validation**, just like we did in Chapter 2.\n",
    "\n",
    "Remember how it works: We take our *training set* (of 60,000 images) and split it into 3 \"folds\" (or \"practice exams\").\n",
    "\n",
    "1. **Run 1:** Train the model on Folds 1 & 2, then test it on Fold 3.\n",
    "\n",
    "2. **Run 2:** Train the model on Folds 1 & 3, then test it on Fold 2.\n",
    "\n",
    "3. **Run 3:** Train the model on Folds 2 & 3, then test it on Fold 1.\n",
    "\n",
    "The `cross_val_score` function does all this for us:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c902a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a814e3eb",
   "metadata": {},
   "source": [
    "- `sgd_clf`: Our classifier.\n",
    "\n",
    "- `X_train`, `y_train_5`: Our training data and the \"5 vs. non-5\" answers.\n",
    "\n",
    "- `cv=3`: \"Use 3 folds.\"\n",
    "\n",
    "- `scoring=\"accuracy\"`: \"Tell me the percentage of correct answers.\"\n",
    "\n",
    "The result is `array([0.95035, 0.96035, 0.9604 ])`.\n",
    "\n",
    "Our first reaction is: **\"WOW! 95-96% accuracy! This is an A+! My model is amazing!\"**\n",
    "\n",
    "...But hold on. This is a classic trap.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 2: The \"Gotcha!\" - Skewed Datasets**\n",
    "Before we celebrate, let's create the \"dumbest possible classifier\" as a baseline.\n",
    "\n",
    "What if we made a model that **always guesses \"not a 5\"**, no matter what image it sees? It doesn't even *look* at the image. It just says \"False, False, False\" for every single one.\n",
    "\n",
    "That's what the `DummyClassifier` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f03f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DummyClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.dummy.DummyClassifier.html\">?<span>Documentation for DummyClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strategy&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;prior&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('constant',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">constant&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "DummyClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77536de2",
   "metadata": {},
   "source": [
    "Now, let's test this dumb model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ab544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90965, 0.90965, 0.90965])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02390ae5",
   "metadata": {},
   "source": [
    "It gets **over 90% accuracy!**\n",
    "\n",
    "How is this possible?\n",
    "\n",
    "Think about our dataset. We have 60,000 images. But how many of them are *actually* 5s? As it turns out, only about 10% of them are 5s. The other 90% are \"non-5s\" (0s, 1s, 2s, 3s, 4s, 6s, 7s, 8s, and 9s).\n",
    "\n",
    "This is a **skewed dataset**: one class (\"non-5\") is *way* more common than the other (\"5\").\n",
    "\n",
    "So, if our dumb classifier *always* guesses \"non-5\", it will be *correct 90% of the time* just by pure chance.\n",
    "\n",
    "**This is the most important lesson of this section:** Our \"smart\" model, which gets 95% accuracy, is only slightly better than a \"dumb\" model that always guesses \"no.\" This tells us that **accuracy is a very poor and misleading performance measure** for skewed datasets. We need a better way to judge our model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b65e3",
   "metadata": {},
   "source": [
    "### **Part 3: The \"Under the Hood\" (Manual Cross-Validation)**\n",
    "The book then shows you a block of code that does the *exact same thing* as `cross_val_score`. Why? Because sometimes you need more control, and it's crucial to understand what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95035\n",
      "0.96035\n",
      "0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "'''\n",
    "This is a smarter way to split our data. The \"Stratified\" part is key. \n",
    "It means \"When you make the 3 folds, please make sure each fold has \n",
    "the same ratio of 5s to non-5s.\" This prevents a fold from randomly \n",
    "having zero 5s, which would make the test useless.\n",
    "'''\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    '''\n",
    "    This is our loop. It will run 3 times (for 3 folds). \n",
    "    In each loop, it gives us two lists:\n",
    "\n",
    "    -> train_index: The indexes of the images to train on (e.g., 40,000 images).\n",
    "\n",
    "    -> test_index: The indexes of the images to test on (e.g., 20,000 images).\n",
    "    '''\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    '''\n",
    "    This is critical. For each fold, we need a fresh, untrained classifier. \n",
    "    We clone our original sgd_clf to get a blank copy. \n",
    "    (We can't just keep re-training the same one, because it would have \n",
    "    already \"learned\" from the other folds).\n",
    "    '''\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds) # We train our fresh clone using only the training data for this specific fold.\n",
    "    y_pred = clone_clf.predict(X_test_fold) # We make our predictions on the hold-out test data for this fold.\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    '''\n",
    "    We compare our predictions (y_pred) to the real answers (y_test_fold) \n",
    "    and sum up all the True values (the ones we got right).\n",
    "    '''\n",
    "    print(n_correct/len(y_pred)) # We print the number correct divided by the total number. This is just the accuracy for that one fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6776a32",
   "metadata": {},
   "source": [
    "After seeing the result we can conclude that  `0.95035`, `0.96035`, and `0.9604`â€”the *exact same numbers* `cross_val_score` gave us.\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. We can measure accuracy with `cross_val_score`.\n",
    "\n",
    "2. Our \"5-detector\" got ~95% accuracy, which *looked* great.\n",
    "\n",
    "3. A \"dumb\" classifier got ~91% accuracy, which proves our dataset is *skewed* (90% \"non-5s\").\n",
    "\n",
    "4. **Therefore, accuracy is a misleading metric for this problem.**\n",
    "\n",
    "This is why the book says we need a much better tool: the **Confusion Matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486581e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Confusion Matrices**\n",
    "\n",
    "Hello again! This is another *fantastic* section. We've just discovered that **accuracy is a trap** for skewed datasets, and now we're going to learn about the *right* way to measure performance.\n",
    "\n",
    "The new tool we'll use is called the Confusion Matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. The \"Clean Predictions\" Problem**\n",
    "\n",
    "To build a confusion matrix, we need a set of predictions to compare against the real answers.\n",
    "\n",
    "- We can't use our **test set**. That's locked in a vault until the very end.\n",
    "\n",
    "- We can't just `fit` our model on `X_train` and then `predict` on `X_train`. The model would be \"cheating\" by making predictions on the exact same data it just studied.\n",
    "\n",
    "We need \"clean\" predictions. This means we need a prediction for *every* image in our training set, but each prediction must be made by a model that **never saw that specific image during training.**\n",
    "\n",
    "How do we do that? With `cross_val_predict`.\n",
    "\n",
    "#### `cross_val_score` **vs.** `cross_val_predict`\n",
    "This is a key difference:\n",
    "\n",
    "- `cross_val_score()`: Does K-fold cross-validation and gives you back the **evaluation scores** (e.g., `[0.95, 0.96, 0.96]`).\n",
    "\n",
    "- `cross_val_predict()`: Does K-fold cross-validation but gives you back the *predictions* for each instance.\n",
    "\n",
    "Think of it like this: With 3 folds (A, B, C):\n",
    "\n",
    "1. A model is trained on B+C, and it makes predictions for **A**.\n",
    "\n",
    "2. A *new* model is trained on A+C, and it makes predictions for **B**.\n",
    "\n",
    "3. A *new* model is trained on A+B, and it makes predictions for **C**.\n",
    "\n",
    "You then stitch together the predictions for A, B, and C, giving you a full, \"clean\" set of predictions for your entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965fe732",
   "metadata": {},
   "source": [
    "Now, `y_train_pred` contains a `True` or `False` guess for all 60,000 images, and we can trust these predictions are \"fair.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **2. The Confusion Matrix: A Report Card of Mistakes**\n",
    "Now we can compare our \"clean\" predictions (`y_train_pred`) with the *real* answers (`y_train_5`). The `confusion_matrix` function gives us a 2x2 grid that shows us *exactly* what kinds of correct guesses and what kinds of mistakes our model made.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638adec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train_5, y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab609638",
   "metadata": {},
   "source": [
    "<img src=\"https://maxbox4.wordpress.com/wp-content/uploads/2021/05/confusiondetectmnist-1.png\" alt=\"Figure 3.3 of chapter 3\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06850521",
   "metadata": {},
   "source": [
    "The image is the perfect visual for this.\n",
    "\n",
    "- **Rows = Actual Class** (The ground truth)\n",
    "\n",
    "- **Columns = Predicted Class** (The model's guess)\n",
    "\n",
    "Here's the result : `array([[53892, 687]`, `[ 1891, 3530]])`\n",
    "\n",
    "Let's break this down:\n",
    "\n",
    "**Top Row: The \"Actual: Not-5\" Class (Negative)**\n",
    "- `53,892` **True Negatives (TN):** These were **Not-5s**, and our model correctly predicted **\"Not-5\"**. This is good! (Top-left in our image).\n",
    "\n",
    "- `687` **False Positives (FP):** These were **Not-5s**, but our model *incorrectly* predicted \"5\". This is a mistake (a \"false alarm\"). (Top-right in our image).\n",
    "\n",
    "**Bottom Row: The \"Actual: 5\" Class (Positive)**\n",
    "- `1,891` **False Negatives (FN):** These were *actual* **5s**, but our model incorrectly predicted \"Not-5\". This is also a mistake (the model \"missed\" it). (Bottom-left in your image).\n",
    "\n",
    "- `3,530` **True Positives (TP):** These were *actual* **5s**, and our model correctly predicted **\"5\"**. This is great! (Bottom-right in your image).\n",
    "\n",
    "A \"perfect\" classifier would have zeros in the FP and FN cells. We have 687 + 1,891 = 2,578 mistakes, and this matrix tells us exactly what kind they were.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1221f",
   "metadata": {},
   "source": [
    "### **3. Beyond the Matrix: Precision and Recall**\n",
    "The 2x2 matrix is awesome, but it's still four numbers. We often want a single, concise metric to summarize performance. This is where **Precision** and **Recall** come in.\n",
    "\n",
    "#### **Precision: The \"How Trustworthy?\" Metric**\n",
    "- **Question:** \"Of all the times my model *predicted* '5', what percentage was it *actually* right?\"\n",
    "\n",
    "- **Formula:** $Precision = \\frac{TP}{TP + FP}$â€‹\n",
    " \n",
    "- **From our numbers:** $3530 / (3530 + 687)$\n",
    "\n",
    "- **Analogy:** Think of a **spam filter**. We want *high precision*. When the filter *predicts* an email is spam (a \"positive\" prediction), we want it to be *very* sure, so it doesn't accidentally put an important email (a False Positive) in your spam folder.\n",
    "\n",
    "#### **Recall: The \"How Thorough?\" Metric**\n",
    "- **Question:** \"Of all the *actual* 5s in the dataset, what percentage did my model *find*?\"\n",
    "\n",
    "- **Formula:** $Recall = \\frac{TP}{TP + FN}$ \n",
    "\n",
    "- **From our numbers:** $3530 / (3530 + 1891)$\n",
    "\n",
    "- **Analogy:** Think of a **medical test for a tumor**. We want *high recall*. We *must* find all the real tumors (True Positives) and avoid missing any (False Negatives). We'd rather have a few false alarms (low precision) than miss a single real case (low recall).\n",
    "\n",
    "**In Summary:**\n",
    "\n",
    "- The **Confusion Matrix** gives us the full picture of our model's mistakes.\n",
    "\n",
    "- **Precision** measures the *quality* of our positive predictions (avoids FPs).\n",
    "\n",
    "- **Recall** measures the *quantity* of our positive predictions (avoids FNs).\n",
    "\n",
    "These two metrics are *much* more informative than simple accuracy, especially for skewed datasets. We'll almost always look at them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9448c96",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Precision and Recall**\n",
    "\n",
    "Alright, we've just learned about the confusion matrix, which gives us the raw numbers for our model's performance. Now we need to turn those raw numbers into meaningful \"grades.\"\n",
    "\n",
    "This is where **Precision** and **Recall** come in.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Calculating Our \"Grades\"**\n",
    "We *could* do the math ourselves using the confusion matrix numbers, but Scikit-Learn gives us handy functions to do it for us: precision_score and recall_score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c7ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5, y_train_pred) # == 3530 / (687 + 3530)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c1ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred) # == 3530 / (1891 + 3530)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435fa18",
   "metadata": {},
   "source": [
    "When we run them on our \"5-detector\" (using the clean `y_train_pred` predictions), we get these scores:\n",
    "\n",
    "- **Precision: 83.7%**\n",
    "\n",
    "- **Recall: 65.1%**\n",
    "\n",
    "Let's translate this. That 95% accuracy we saw earlier? It was a lie. Here's the truth:\n",
    "\n",
    "1. **Precision (83.7%):** This is our \"trustworthiness\" grade. When our model *claims* an image is a 5 (a positive prediction), it's only right 83.7% of the time. The other 16.3% of the time, it's a \"false alarm\" (a False Positive).\n",
    "\n",
    "2. **Recall (65.1%):** This is our \"thoroughness\" grade. Of *all* the real 5s in the training set, our model only *found* 65.1% of them. It completely *missed* the other ~35% (those are the False Negatives).\n",
    "\n",
    "So, our 5-detector is actually not that great. It's overconfident (it makes a lot of false claims) and it's not very observant (it misses a lot of the real 5s).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746806b7",
   "metadata": {},
   "source": [
    "### **2. The F1-Score: The \"GPA\"**\n",
    "\n",
    "Often, you'll have two different models.\n",
    "\n",
    "- Model A: 90% precision, 50% recall\n",
    "\n",
    "- Model B: 50% precision, 90% recall\n",
    "\n",
    "Which one is \"better\"? It's hard to compare. We need a single number, like a **GPA**, that summarizes both grades. This is the **F1-Score**.\n",
    "\n",
    "#### **The F1 Score Formula**\n",
    "**1. The Most common Formula:**\n",
    "\n",
    "This is the easiest one to remember and use if you already have your precision and recall scores:\n",
    "\n",
    "   $$F_1 = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "Think of it this way: it's like a balanced average, but it *heavily punishes* low scores.\n",
    "- If you have 100% precision (1.0) and 0% recall (0.0), a simple average would be 50%.\n",
    "- The F1 score would be $2 \\times \\frac{1.0 \\times 0.0}{1.0 + 0.0} = 0$. This is a much truer reflection of that model's performanceâ€”it's useless!\n",
    "\n",
    "**2. The \"Definition\" Formula (Harmonic Mean)**\n",
    "\n",
    "This formula, also in your book, shows *why* it's called the harmonic mean. It looks a bit more complex, but it's the formal definition:\n",
    "\n",
    "$$F_1 = \\frac{2}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}}$$\n",
    "\n",
    "(If you do the algebra, you'll see this is exactly the same as the first formula).\n",
    "\n",
    "**3. The Raw Number Formula:**\n",
    "\n",
    "This formula lets you calculate the F1 score directly from your confusion matrix values: **True Positives (TP), False Positives (FP),** and **False Negatives (FN).**\n",
    "\n",
    "$$F_1 = \\frac{TP}{TP + \\frac{FN + FP}{2}}$$\n",
    "\n",
    "This is just plugging the formulas for precision ($TP / (TP + FP)$) and recall ($TP / (TP + FN)$) into the first equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61024402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343847"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn .metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8303920",
   "metadata": {},
   "source": [
    "The F1-Score is the **harmonic mean** of precision and recall.\n",
    "\n",
    "Now, why a *harmonic* mean? Why not a simple average?\n",
    "\n",
    "A simple average is too forgiving. If a model had 100% precision but 0% recall, a simple average would be 50%. That's a \"C\" grade, which is misleading! That model is *terrible*â€”it finds nothing!\n",
    "\n",
    "The harmonic mean gives much more weight to *low* values. To get a high F1-score, **both** precision and recall *must* be high.\n",
    "\n",
    "- A 100% and 0% would give you an F1-score of **0%**.\n",
    "\n",
    "- A 50% and 50% would give you an F1-score of **50%**.\n",
    "\n",
    "- A 90% and 90% would give you an F1-score of **90%**.\n",
    "\n",
    "Our model's F1-score is **73.2%**. This confirms our feeling: it's a C/B- student. It's a single, balanced number that tells us the model is \"okay,\" but not great.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb58cc",
   "metadata": {},
   "source": [
    "### **3. Context is King: Do You Want a \"Specialist\" or a \"Net\"?**\n",
    "\n",
    "So, is a balanced F1-score always what we want? **Absolutely not**.\n",
    "\n",
    "This is the most important lesson. The \"best\" metric depends *entirely* on your project's goal. You must choose between prioritizing Precision or Recall.\n",
    "\n",
    "#### **Scenario 1: Prioritize PRECISION (The \"Safe for Kids\" Filter ðŸ›¡ï¸)**\n",
    "\n",
    "- **Your Goal:** You're building a classifier to find kid-safe videos.\n",
    "\n",
    "- **A \"positive\" prediction is:** \"This video is safe for kids.\"\n",
    "\n",
    "- **What's a False Positive (FP)?** A *bad* video is incorrectly labeled \"safe.\"\n",
    "\n",
    "- **What's a False Negative (FN)?** A *good* video is incorrectly labeled \"bad.\"\n",
    "\n",
    "**Which mistake is worse?** The **False Positive** is a *catastrophe*. You let a bad video through. The False Negative is just an annoyance (a kid misses a good video).\n",
    "\n",
    "**Your Strategy:** You need *extremely high precision*. You'd rather block 100 good videos (low recall) than let one bad video slip through.\n",
    "\n",
    "#### **Scenario 2: Prioritize RECALL (The \"Shoplifter\" Detector ðŸš¨)**\n",
    "\n",
    "- **Your Goal:** You're building a classifier to detect shoplifters on camera.\n",
    "\n",
    "- **A \"positive\" prediction is:** \"That person is shoplifting.\"\n",
    "\n",
    "- **What's a False Positive (FP)?** An *innocent* person is flagged.\n",
    "\n",
    "- **What's a False Negative (FN)?** A real *shoplifter* is *not* flagged.\n",
    "\n",
    "**Which mistake is worse?** The **False Negative** is a *catastrophe*. You just lost merchandise! The False Positive is just an annoyance (a security guard has to check a false alert).\n",
    "\n",
    "**Your Strategy:** You need *extremely high recall*. You want to *find every single shoplifter*. You are perfectly fine with 10 false alarms (low precision) if it means you catch almost all the real thieves (high recall).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f9ef9",
   "metadata": {},
   "source": [
    "### **4. The Precision/Recall Trade-off**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8105d288",
   "metadata": {},
   "source": [
    "This leads us to the final, fundamental concept: **we can't have it both ways**.\n",
    "\n",
    "- If we want **higher precision**, we have to be *stricter*. we tell our model, \"Don't flag it unless you're 99% sure!\" This will give us fewer FPs (high precision) but we will *miss* more real cases (low recall).\n",
    "\n",
    "- If we want **higher recall**, we have to be *more lenient*. we tell our model, \"Flag it if you're even 30% sure!\" This will help us *find* almost all the real cases (high recall) but we'll get a *ton* of false alarms (low precision).\n",
    "\n",
    "This is the **Precision/Recall Trade-off.** Our job as an engineer isn't to get 100% on both; it's to decide where on this curve is the right balance for *our* specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ce9e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
